{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from typing import Final\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report, multilabel_confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the complete dataset\n",
    "\n",
    "gdp_raw = pd.read_excel('gdp.xlsx').set_axis(\n",
    "    ['county', '2017', '2018', '2019', '2020', 'rank 2018', 'percent change 2018', 'percent change 2019', 'percent change 2020', 'rank 2020'], axis=1, inplace=False)\n",
    "gdp_clean: pd.DataFrame = gdp_raw.drop(columns=['rank 2018', '2017', '2018', '2020',\n",
    "                                                'rank 2020', 'percent change 2018', 'percent change 2019'], inplace=False).iloc[5:3222]\n",
    "\n",
    "state_names = pd.read_csv('us-counties-2020.csv')['state'].unique()\n",
    "\n",
    "counties_df = pd.read_csv('complete.csv')\n",
    "counties_df['2019 raw GDP'] = np.nan  # iloc =5\n",
    "counties_df['percent change 2020'] = np.nan  # iloc = 6\n",
    "\n",
    "curr_state = None\n",
    "for index, row in gdp_clean.iterrows():\n",
    "    if row[0] in state_names:\n",
    "        curr_state = row[0]\n",
    "        continue\n",
    "    else:\n",
    "        row_index = counties_df.index[(counties_df['state'] == curr_state) & (\n",
    "            counties_df['county'] == row[0])].tolist()\n",
    "        counties_df.iloc[[row_index], [5]] = row[1]  # type: ignore\n",
    "        counties_df.iloc[[row_index], [6]] = row[2]  # type: ignore\n",
    "\n",
    "\n",
    "print(f\"{len(counties_df['state'].unique())} states\")\n",
    "counties_df['2019 raw GDP'] = counties_df['2019 raw GDP'].astype('float32')\n",
    "print(counties_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_state_names = pd.get_dummies(counties_df['state'])\n",
    "counties_df = counties_df.drop(columns=['state']).join(encoded_state_names)\n",
    "counties_df.dropna(axis='index', how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some constants\n",
    "DEFAULT_LEARNING_RATE: Final[float] = 0.3\n",
    "DEFAULT_EPOCHS: Final[int] = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildDefaultModel():\n",
    "    SGD_optimizer: Final = tf.keras.optimizers.SGD(\n",
    "        learning_rate=DEFAULT_LEARNING_RATE)\n",
    "    lossFunction = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "    model: keras.Sequential = keras.Sequential([\n",
    "        keras.Input(shape=(59)),\n",
    "        tf.keras.layers.Dense(\n",
    "            units=12, activation='ReLU', name='hidden_layer_1'),\n",
    "        tf.keras.layers.Dense(\n",
    "            units=12, activation='ReLU', name='hidden_layer_2'),\n",
    "        tf.keras.layers.Dense(\n",
    "            units=6, activation='ReLU', name='hidden_layer_3'),\n",
    "        tf.keras.layers.Dense(\n",
    "            units=5, activation='ReLU', name='hidden_layer_4'),\n",
    "        tf.keras.layers.Dense(units=1, activation='ReLU', name='output'),\n",
    "    ], name='Default_COVID_Classifier')\n",
    "\n",
    "    model.compile(loss=lossFunction, optimizer=SGD_optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "defaultCovidClassifier = BuildDefaultModel()\n",
    "print(defaultCovidClassifier.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_attributes = counties_df.drop(columns=['percent change 2020', 'county'], inplace=False)\n",
    "\n",
    "input_attributes['2019 raw GDP'] = input_attributes['2019 raw GDP'].astype('float64')\n",
    "input_attributes['cases'] = input_attributes['cases'].astype('int32')\n",
    "\n",
    "\n",
    "input_attributes['Positivity Rate'] = input_attributes['cases'] / input_attributes['2020 population']\n",
    "input_attributes['Death Rate'] = input_attributes['deaths'] / input_attributes['2020 population']\n",
    "input_attributes.drop(columns=['cases', 'deaths'], inplace=True)\n",
    "\n",
    "normalizedAttributes: Final[pd.DataFrame] = pd.DataFrame(\n",
    "    MinMaxScaler()\n",
    "    .fit(input_attributes)\n",
    "    .transform(input_attributes)\n",
    ")\n",
    "print(input_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normalizedAttributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train, X_Test, y_Train, y_Test = train_test_split(\n",
    "    input_attributes, counties_df['percent change 2020'].astype('float64'), test_size=0.1, random_state=44)\n",
    "\n",
    "print(X_Train.shape, y_Train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and Train\n",
    "startTime = time.time()\n",
    "defaultCovidClassifier.fit(\n",
    "    x=X_Train, y=y_Train,\n",
    "    epochs=DEFAULT_EPOCHS,\n",
    "    validation_data=(X_Test, y_Test))\n",
    "endTime = time.time()\n",
    "\n",
    "print(f'Training took {endTime-startTime} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the MSE, Accuracy Score, and Confusion Matrices\n",
    "\n",
    "predicted_y: np.ndarray = defaultCovidClassifier.predict(\n",
    "    X_Test)  # raw continuous outputs\n",
    "# predicted_y_argmaxed = predicted_y.argmax(axis=1)\n",
    "\n",
    "print(f'MSE of test set is: {mean_squared_error(predicted_y, y_Test)}')\n",
    "# print(f'Accuracy: {accuracy_score(predicted_y, y_Test)}')\n",
    "\n",
    "# print('Precision & Recall:')\n",
    "# print(classification_report(predicted_y, y_Test))\n",
    "\n",
    "# This prints an array of 7 matrices, each matrix is 2x2 of [[TT, TF], [FT, FF]]\n",
    "# Where each index represents the corresponding class name\n",
    "# in the OneHotEncoding function in the above cell\n",
    "# print('Confusion Matrix:')\n",
    "# print(multilabel_confusion_matrix(\n",
    "#     y_pred=predicted_y, y_true=y_Test.argmax(axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateValidationData(inputDF: pd.DataFrame, expectedOutputs: np.ndarray,\n",
    "                           trainIndexes: np.ndarray,\n",
    "                           testIndexes: np.ndarray):\n",
    "    X_Train = inputDF.iloc[trainIndexes]\n",
    "    X_Test = inputDF.iloc[testIndexes]\n",
    "\n",
    "    y_Train = expectedOutputs[trainIndexes]\n",
    "    y_Test = expectedOutputs[testIndexes]\n",
    "\n",
    "    return X_Train, X_Test, y_Train, y_Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do 10-fold validation\n",
    "\n",
    "KFolder = KFold(n_splits=10)\n",
    "mseScores: list[float] = []\n",
    "accuracyScores: list[float] = []\n",
    "\n",
    "for trainIndexes, testIndexes in KFolder.split(input_attributes):\n",
    "    X_Train, X_Test, y_Train, y_Test = generateValidationData(\n",
    "        input_attributes, encodedClassNames, trainIndexes, testIndexes)\n",
    "\n",
    "    beansClassifier.fit(\n",
    "        x=X_Train, y=y_Train,\n",
    "        epochs=DEFAULT_EPOCHS,\n",
    "        validation_data=(X_Test, y_Test))\n",
    "\n",
    "    predicted_y: np.ndarray = beansClassifier.predict(X_Test)\n",
    "\n",
    "    mseScores.append(mean_squared_error(y_Test, predicted_y))\n",
    "    accuracyScores.append(accuracy_score(\n",
    "        predicted_y.argmax(axis=1), y_Test.argmax(axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f'Accuracy Scores: {accuracyScores}\\nAverage accuracy is: {np.average(accuracyScores)}\\n')\n",
    "print(f'MSE Loss: {mseScores}\\nAverage MSE is: {np.average(mseScores)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildModel(numNodesLayer1=12, numNodesLayer2=3, learningRate=DEFAULT_LEARNING_RATE):\n",
    "    SGD_optimizer: Final = tf.keras.optimizers.SGD(learning_rate=learningRate)\n",
    "    lossFunction: Final = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "    model: keras.Sequential = keras.Sequential([\n",
    "        tf.keras.layers.Dense(\n",
    "            input_dim=6,\n",
    "            units=numNodesLayer1, activation='ReLU', name='hidden_layer_1'),\n",
    "        tf.keras.layers.Dense(\n",
    "            units=numNodesLayer2, activation='ReLU', name='hidden_layer_2'),\n",
    "        tf.keras.layers.Dense(units=1, activation='ReLU', name='output'),\n",
    "    ], name='Beans_Classifier')\n",
    "\n",
    "    model.compile(loss=lossFunction, optimizer=SGD_optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "wrappedCovidClassifier = KerasClassifier(build_fn=BuildModel)\n",
    "\n",
    "# parameters passed to BuildModel(...)\n",
    "param_grid = dict(\n",
    "    nb_epoch=np.array(list(range(500, 1001, 50))),\n",
    "    learningRate=np.array([0.1, 0.3, 0.6]),\n",
    "    numNodesLayer1=np.array([12, 13, 14]),\n",
    "    numNodesLayer2=np.array([3, 4, 5]),\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(estimator=wrappedCovidClassifier,\n",
    "                    param_grid=param_grid, n_jobs=-1, cv=10)\n",
    "\n",
    "grid_result = grid.fit(X_Train, y_Train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big reveal of best parameters\n",
    "grid_result.best_params_"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
