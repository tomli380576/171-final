{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import time\n",
    "\n",
    "from typing import Final\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report, multilabel_confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneHotEncoding(df: pd.Series) -> np.ndarray:\n",
    "    encodedClassNames: list[list[int]] = []\n",
    "    for i in range(df.shape[0]):\n",
    "        strClassName = str(df.iloc[i])\n",
    "        encodedClassName = [\n",
    "            int(strClassName == 'SEKER'),\n",
    "            int(strClassName == 'BARBUNYA'),\n",
    "            int(strClassName == 'BOMBAY'),\n",
    "            int(strClassName == 'CALI'),\n",
    "            int(strClassName == 'DERMASON'),\n",
    "            int(strClassName == 'HOROZ'),\n",
    "            int(strClassName == 'SIRA')\n",
    "        ]\n",
    "        if encodedClassName == [0, 0, 0, 0, 0, 0, 0]:\n",
    "            raise ValueError(f'Unknown Class Name: {strClassName}')\n",
    "        else:\n",
    "            encodedClassNames.append(encodedClassName)\n",
    "\n",
    "    return np.asarray(encodedClassNames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "rawData: Final[pd.DataFrame] = pd.read_csv('./Dry_Beans_Dataset.csv')\n",
    "inputAttributes: Final[pd.DataFrame] = rawData.drop(\n",
    "    columns=['Class'], inplace=False)\n",
    "\n",
    "# One hot encoding\n",
    "encodedClassNames: Final[np.ndarray] = OneHotEncoding(rawData['Class'])\n",
    "\n",
    "# Normalization\n",
    "normalizedAttributes: Final[pd.DataFrame] = pd.DataFrame(\n",
    "    MinMaxScaler()\n",
    "    .fit(inputAttributes)\n",
    "    .transform(inputAttributes)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some constants\n",
    "DEFAULT_LEARNING_RATE: Final[float] = 0.3\n",
    "DEFAULT_EPOCHS: Final[int] = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildDefaultModel():\n",
    "    SGD_optimizer: Final = tf.keras.optimizers.SGD(\n",
    "        learning_rate=DEFAULT_LEARNING_RATE)\n",
    "    lossFunction = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "    model: keras.Sequential = keras.Sequential([\n",
    "        keras.Input(shape=(16)),\n",
    "        tf.keras.layers.Dense(\n",
    "            units=12, activation='sigmoid', name='hidden_layer_1'),\n",
    "        tf.keras.layers.Dense(\n",
    "            units=3, activation='sigmoid', name='hidden_layer_2'),\n",
    "        tf.keras.layers.Dense(units=7, activation='sigmoid', name='output'),\n",
    "    ], name='Beans_Classifier')\n",
    "\n",
    "    model.compile(loss=lossFunction, optimizer=SGD_optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "beansClassifier = BuildDefaultModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train, X_Test, y_Train, y_Test = train_test_split(\n",
    "    normalizedAttributes, encodedClassNames, test_size=0.1, random_state=44)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and Train\n",
    "startTime = time.time()\n",
    "beansClassifier.fit(\n",
    "    x=X_Train, y=y_Train,\n",
    "    epochs=DEFAULT_EPOCHS,\n",
    "    validation_data=(X_Test, y_Test), verbose='2')\n",
    "endTime = time.time()\n",
    "\n",
    "print(f'Training took {endTime-startTime} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the MSE, Accuracy Score, and Confusion Matrices\n",
    "\n",
    "predicted_y: np.ndarray = beansClassifier.predict(\n",
    "    X_Test)  # raw continuous outputs\n",
    "predicted_y_argmaxed = predicted_y.argmax(axis=1)\n",
    "\n",
    "print(f'MSE of test set is: {mean_squared_error(predicted_y, y_Test)}')\n",
    "print(f'Accuracy: {accuracy_score(predicted_y_argmaxed, y_Test.argmax(1))}')\n",
    "\n",
    "print('Precision & Recall:')\n",
    "print(classification_report(predicted_y_argmaxed, y_Test.argmax(1)))\n",
    "\n",
    "# This prints an array of 7 matrices, each matrix is 2x2 of [[TT, TF], [FT, FF]]\n",
    "# Where each index represents the corresponding class name\n",
    "# in the OneHotEncoding function in the above cell\n",
    "print('Confusion Matrix:')\n",
    "print(multilabel_confusion_matrix(\n",
    "    y_pred=predicted_y_argmaxed, y_true=y_Test.argmax(axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateValidationData(inputDF: pd.DataFrame, expectedOutputs: np.ndarray,\n",
    "                           trainIndexes: np.ndarray,\n",
    "                           testIndexes: np.ndarray):\n",
    "    X_Train = inputDF.iloc[trainIndexes]\n",
    "    X_Test = inputDF.iloc[testIndexes]\n",
    "\n",
    "    y_Train = expectedOutputs[trainIndexes]\n",
    "    y_Test = expectedOutputs[testIndexes]\n",
    "\n",
    "    return X_Train, X_Test, y_Train, y_Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do 10-fold validation\n",
    "\n",
    "KFolder = KFold(n_splits=10)\n",
    "mseScores: list[float] = []\n",
    "accuracyScores: list[float] = []\n",
    "\n",
    "for trainIndexes, testIndexes in KFolder.split(normalizedAttributes):\n",
    "    X_Train, X_Test, y_Train, y_Test = generateValidationData(\n",
    "        normalizedAttributes, encodedClassNames, trainIndexes, testIndexes)\n",
    "\n",
    "    beansClassifier.fit(\n",
    "        x=X_Train, y=y_Train,\n",
    "        epochs=DEFAULT_EPOCHS,\n",
    "        validation_data=(X_Test, y_Test))\n",
    "\n",
    "    predicted_y: np.ndarray = beansClassifier.predict(X_Test)\n",
    "\n",
    "    mseScores.append(mean_squared_error(y_Test, predicted_y))\n",
    "    accuracyScores.append(accuracy_score(\n",
    "        predicted_y.argmax(axis=1), y_Test.argmax(axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f'Accuracy Scores: {accuracyScores}\\nAverage accuracy is: {np.average(accuracyScores)}\\n')\n",
    "print(f'MSE Loss: {mseScores}\\nAverage MSE is: {np.average(mseScores)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildModel(numNodesLayer1=12, numNodesLayer2=3, learningRate=DEFAULT_LEARNING_RATE):\n",
    "    SGD_optimizer: Final = tf.keras.optimizers.SGD(learning_rate=learningRate)\n",
    "    lossFunction = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "    model: keras.Sequential = keras.Sequential([\n",
    "        tf.keras.layers.Dense(\n",
    "            input_dim=6,\n",
    "            units=numNodesLayer1, activation='ReLU', name='hidden_layer_1'),\n",
    "        tf.keras.layers.Dense(\n",
    "            units=numNodesLayer2, activation='ReLU', name='hidden_layer_2'),\n",
    "        tf.keras.layers.Dense(units=1, activation='ReLU', name='output'),\n",
    "    ], name='Beans_Classifier')\n",
    "\n",
    "    model.compile(loss=lossFunction, optimizer=SGD_optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "wrappedBeansClassifier = KerasClassifier(build_fn=BuildModel)\n",
    "\n",
    "# parameters passed to BuildModel(...)\n",
    "param_grid = dict(\n",
    "    nb_epoch=np.array(list(range(500, 1001, 50))),\n",
    "    learningRate=np.array([0.1, 0.3, 0.6]),\n",
    "    numNodesLayer1=np.array([12, 13, 14]),\n",
    "    numNodesLayer2=np.array([3, 4, 5]),\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(estimator=wrappedBeansClassifier,\n",
    "                    param_grid=param_grid, n_jobs=-1, cv=10)\n",
    "\n",
    "grid_result = grid.fit(X_Train, y_Train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big reveal of best parameters\n",
    "grid_result.best_params_"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
